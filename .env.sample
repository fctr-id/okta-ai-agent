
OKTA_CLIENT_ORGURL=https://dev-271805.okta.com
# this is the API token for the Okta API. You can generate this from the Okta Admin Console
# A read-only admin privilege is sufficient for this tool
# Make sure you increate the API limits for this token so the data fetch process is faster.
# https://help.okta.com/en-us/content/topics/security/api.htm?cshid=ext_API#Set
OKTA_CLIENT_TOKEN=
DATABASE_URL=sqlite:///sqllite_db/okta_sync.db  # DO NOT CHANGE THIS
SYNC_INTERVAL_HOURS=1
LOG_LEVEL=INFO

# Number of parallelr threads to ingest data from OKTA API. Need to plya around depending on the API rate limits for the org
NUM_OF_THREADS=4

#Can be set to True or False
USE_PRE_REASONING=True

# AI Provider Selection. IT can be one of the following values: vertex_ai, openai, azure_openai, openai_compatible
AI_PROVIDER=openai

# Vertex AI Models (if using Vertex AI)
VERTEX_AI_SERVICE_ACCOUNT_FILE=path/to/service-account.json   ## or set GOOGLE_APPLICATION_CREDENTIALS environment variable
VERTEX_AI_CODING_MODEL=gemini-1.5-pro
VERTEX_AI_REASONING_MODEL=gemini-1.5-pro

# OpenAI Models (if using OpenAI)
OPENAI_API_KEY=
OPENAI_REASONING_MODEL=gpt-4o
OPENAI_CODING_MODEL=gpt-4o

# Azure OpenAI Models (if using Azure)
AZURE_OPENAI_KEY=your-api-key
AZURE_OPENAI_ENDPOINT=your-endpoint
AZURE_OPENAI_VERSION=2024-07-01-preview
AZURE_OPENAI_REASONING_MODEL=gpt-4
AZURE_OPENAI_CODING_MODEL=gpt-4-turbo

# OpenAI Compatible Configuration
OPENAI_COMPATIBLE_REASONING_MODEL=accounts/fireworks/models/qwen2p5-72b-instruct
OPENAI_COMPATIBLE_CODING_MODEL=accounts/fireworks/models/qwen2p5-coder-32b-instruct
OPENAI_COMPATIBLE_BASE_URL=https://api.fireworks.ai/inference/v1
OPENAI_COMPATIBLE_TOKEN=